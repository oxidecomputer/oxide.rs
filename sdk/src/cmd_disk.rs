use crate::types::{
    BlockSize, ByteCount, DiskCreate, DiskSource, FinalizeDisk, ImageCreate, ImageSource,
    ImportBlocksBulkWrite, Name, NameOrId,
};
use crate::{Client, Error, ResponseValue};
use serde::{Deserialize, Serialize};
use std::path::PathBuf;

/// Create a disk from a file upload
#[derive(Clone, Debug, Deserialize, Serialize, schemars :: JsonSchema)]
pub struct DiskImport {
    pub description: String,
    /// The name of the disk to create
    pub disk: Name,
    /// The desired size of the disk's blocks
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub disk_block_size: Option<BlockSize>,
    /// The size of the disk to create. If unspecified, the size of the file
    /// will be used, rounded up to the nearest GB.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub disk_size: Option<ByteCount>,
    /// If supplied, create an image with the given name. Requires the creation
    /// of a snapshot.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub image: Option<Name>,
    /// The description for the image created out of the snapshot of this
    /// disk.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub image_description: Option<String>,
    /// The OS of this image (e.g. Debian)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub image_os: Option<String>,
    /// The version of this image (e.g. 11, focal, a9e77e3a,
    /// 2023-04-06T14:23:34Z)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub image_version: Option<String>,
    /// Path to the file to import
    pub path: PathBuf,
    /// Name or ID of the project
    pub project: NameOrId,
    /// If supplied, create a snapshot with the given name.
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub snapshot: Option<Name>,
    /// Print progress and error messages
    pub extra_out: bool,
}

// We don't want to actually specify this in oxide.json but it's really useful
// to have this auto generated. This was generated via putting it in oxide.json
// and copying the output
pub mod builder {
    use super::NameOrId;
    use super::{
        BlockSize, DiskCreate, DiskSource, Error, FinalizeDisk, ImageCreate, ImageSource,
        ImportBlocksBulkWrite, ResponseValue,
    };
    use crate::{ClientDisksExt, ClientImagesExt, ClientSnapshotsExt};
    use base64::Engine;
    use indicatif::{ProgressBar, ProgressStyle};
    use std::fs::File;
    use std::io::Read;
    use std::path::PathBuf;
    use std::sync::Arc;
    use tokio::sync::mpsc;

    #[derive(Clone, Debug)]
    pub struct DiskImport<'a> {
        client: &'a super::Client,
        description: Result<String, String>,
        disk: Result<super::Name, String>,
        disk_block_size: Result<Option<super::BlockSize>, String>,
        disk_size: Result<Option<super::ByteCount>, String>,
        image: Result<Option<super::Name>, String>,
        image_description: Result<Option<String>, String>,
        image_os: Result<Option<String>, String>,
        image_version: Result<Option<String>, String>,
        path: Result<super::PathBuf, String>,
        project: Result<super::NameOrId, String>,
        snapshot: Result<Option<super::Name>, String>,
        extra_output: Result<bool, String>,
    }

    impl<'a> DiskImport<'a> {
        pub fn new(client: &'a super::Client) -> Self {
            Self {
                client: client,
                description: Err("no value supplied for description".to_string()),
                disk: Err("no value supplied for disk".to_string()),
                disk_block_size: Ok(Default::default()),
                disk_size: Ok(Default::default()),
                image: Ok(Default::default()),
                image_description: Ok(Default::default()),
                image_os: Ok(Default::default()),
                image_version: Ok(Default::default()),
                path: Err("no value supplied for path".to_string()),
                project: Err("no value supplied for project".to_string()),
                snapshot: Ok(Default::default()),
                extra_output: Ok(Default::default()),
            }
        }

        // This is all autogenerated
        pub fn description<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<String>,
            T::Error: std::fmt::Display,
        {
            self.description = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for description: {}", e));
            self
        }
        pub fn disk<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<super::Name>,
            T::Error: std::fmt::Display,
        {
            self.disk = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for disk: {}", e));
            self
        }
        pub fn disk_block_size<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<Option<super::BlockSize>>,
            T::Error: std::fmt::Display,
        {
            self.disk_block_size = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for disk_block_size: {}", e));
            self
        }
        pub fn disk_size<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<Option<super::ByteCount>>,
            T::Error: std::fmt::Display,
        {
            self.disk_size = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for disk_size: {}", e));
            self
        }
        pub fn extra_output<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<bool>,
            T::Error: std::fmt::Display,
        {
            self.extra_output = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for extra_output: {}", e));
            self
        }

        pub fn image<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<Option<super::Name>>,
            T::Error: std::fmt::Display,
        {
            self.image = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for image: {}", e));
            self
        }
        pub fn image_description<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<Option<String>>,
            T::Error: std::fmt::Display,
        {
            self.image_description = value.try_into().map_err(|e| {
                format!(
                    "error converting supplied value for image_description: {}",
                    e
                )
            });
            self
        }
        pub fn image_os<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<Option<String>>,
            T::Error: std::fmt::Display,
        {
            self.image_os = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for image_os: {}", e));
            self
        }
        pub fn image_version<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<Option<String>>,
            T::Error: std::fmt::Display,
        {
            self.image_version = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for image_version: {}", e));
            self
        }
        pub fn path<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<super::PathBuf>,
            T::Error: std::fmt::Display,
        {
            self.path = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for path: {}", e));
            self
        }
        pub fn project<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<super::NameOrId>,
            T::Error: std::fmt::Display,
        {
            self.project = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for project: {}", e));
            self
        }
        pub fn snapshot<T>(mut self, value: T) -> Self
        where
            T: std::convert::TryInto<Option<super::Name>>,
            T::Error: std::fmt::Display,
        {
            self.snapshot = value
                .try_into()
                .map_err(|e| format!("error converting supplied value for snapshot: {}", e));
            self
        }
    }

    impl DiskImport<'_> {
        pub async fn send(self) -> Result<ResponseValue<()>, Error<crate::types::Error>> {
            let path = self
                .path
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let description = self
                .description
                .as_ref()
                .map_err(|e| e.to_string())
                .map_err(Error::InvalidRequest)?;
            let project = self
                .project
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let disk = self
                .disk
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let extra_out = *self
                .extra_output
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;

            if !std::path::Path::new(&path).exists() {
                return Err(Error::InvalidRequest(format!(
                    "path {} does not exist",
                    path.to_string_lossy()
                )));
            }

            // validate that objects don't exist already
            err_if_object_exists(
                format!("disk {:?} exists already", &disk),
                self.client
                    .disk_view()
                    .project(project)
                    .disk(NameOrId::Name(disk.clone()))
                    .send()
                    .await,
            )?;

            // snapshot
            if let Some(snapshot_name) = &self
                .snapshot
                .as_ref()
                .map_err(|e| e.to_string())
                .map_err(Error::InvalidRequest)?
            {
                err_if_object_exists(
                    format!("snapshot {:?} exists already", &snapshot_name),
                    self.client
                        .snapshot_view()
                        .project(project)
                        .snapshot(NameOrId::Name(snapshot_name.clone()))
                        .send()
                        .await,
                )?;
            }

            // image
            if let Some(image_name) = &self
                .image
                .as_ref()
                .map_err(|e| e.to_string())
                .map_err(Error::InvalidRequest)?
            {
                err_if_object_exists(
                    format!("image {:?} exists already", &image_name),
                    self.client
                        .image_view()
                        .project(project)
                        .image(NameOrId::Name(image_name.clone()))
                        .send()
                        .await,
                )?;
            }

            let file_size = std::fs::metadata(&path)
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?
                .len();
            let disk_size = get_disk_size(
                &path,
                self.disk_size
                    .as_ref()
                    .map_err(|e| e.to_string())
                    .map_err(Error::InvalidRequest)?
                    .as_ref()
                    .map(|x| **x),
            )?;

            let disk_block_size = match &self
                .disk_block_size
                .as_ref()
                .map_err(|e| e.to_string())
                .map_err(Error::InvalidRequest)?
            {
                Some(v) => v.clone(),
                None => BlockSize::try_from(512).unwrap(),
            };

            if (file_size % *disk_block_size as u64) != 0 {
                return Err(Error::InvalidRequest(format!(
                    "file size {} is not divisible by block size{}!",
                    file_size, *disk_block_size
                )));
            }

            // Use 8 upload tasks - this evenly divides all block sizes, and we know
            // that the file size is evenly divided by the selected block size due
            // to the above check.
            const UPLOAD_TASKS: usize = 8;

            // Create the disk in state "importing blocks"
            self.client
                .disk_create()
                .project(project)
                .body(DiskCreate {
                    name: disk.clone(),
                    description: description.clone(),
                    disk_source: DiskSource::ImportingBlocks {
                        block_size: disk_block_size.clone(),
                    },
                    size: disk_size.into(),
                })
                .send()
                .await?;

            // Start the bulk write process
            let start_bulk_write_response = self
                .client
                .disk_bulk_write_import_start()
                .project(project)
                .disk(disk.clone())
                .send()
                .await;

            if let Err(e) = start_bulk_write_response {
                if extra_out {
                    eprintln!("starting the bulk write process failed with {:?}", e);
                }

                // If this fails, the disk is in state import-ready. Finalize it so
                // it can be deleted.
                self.unwind_disk_finalize().await?;

                // The finalize succeeded, so delete the disk.
                self.unwind_disk_delete().await?;

                // Finalizing and deleting the disk succeeded, so return the
                // original error.
                return Err(e);
            }

            // Create one tokio task for each thread that will upload file chunks
            let mut handles: Vec<tokio::task::JoinHandle<Result<(), Error<crate::types::Error>>>> =
                Vec::with_capacity(UPLOAD_TASKS);
            let mut senders = Vec::with_capacity(UPLOAD_TASKS);

            let pb = if extra_out {
                let pb = Arc::new(ProgressBar::new(file_size));
                pb.set_style(ProgressStyle::default_bar()
            .template("[{elapsed_precise}] [{wide_bar:.green}] {bytes}/{total_bytes} ({bytes_per_sec}, {eta})")
                .map_err(|x| x.to_string()).map_err(Error::InvalidRequest)?
            );
                pb.set_position(0);
                Some(pb)
            } else {
                None
            };

            for _i in 0..UPLOAD_TASKS {
                let (tx, mut rx) = mpsc::channel(100);

                let client = self.client.clone();
                let disk_name = disk.clone();
                let project = project.clone();

                let pb = pb.clone();

                handles.push(tokio::spawn(async move {
                    while let Some((offset, base64_encoded_data, data_len)) = rx.recv().await {
                        client
                            .disk_bulk_write_import()
                            .disk(disk_name.clone())
                            .project(project.clone())
                            .body(ImportBlocksBulkWrite {
                                offset,
                                base64_encoded_data,
                            })
                            .send()
                            .await?;

                        if let Some(x) = pb.as_ref() {
                            x.inc(data_len as u64)
                        }
                    }

                    Ok(())
                }));

                senders.push(tx);
            }

            // Read chunks from the file in the file system and send them to the
            // upload threads.
            let mut file = File::open(&path)
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let mut i = 0;
            let mut offset = 0;

            // Upload to Nexus in 512k byte chunks
            const CHUNK_SIZE: u64 = 512 * 1024;

            let read_result: Result<(), _> = loop {
                let mut chunk = Vec::with_capacity(CHUNK_SIZE as usize);

                let n = match file.by_ref().take(CHUNK_SIZE).read_to_end(&mut chunk) {
                    Ok(n) => n,
                    Err(e) => {
                        let error_msg = format!(
                            "reading from {} failed with {:?}",
                            path.to_string_lossy(),
                            e
                        );
                        if extra_out {
                            eprintln!("{}", error_msg);
                        }
                        break Err(Error::InvalidRequest(error_msg));
                    }
                };

                if n == 0 {
                    break Ok(());
                }

                // If the chunk we just read is all zeroes, don't POST it.
                if !chunk.iter().all(|x| *x == 0) {
                    let encoded = base64::engine::general_purpose::STANDARD.encode(&chunk[0..n]);

                    if let Err(e) = senders[i % UPLOAD_TASKS].send((offset, encoded, n)).await {
                        let error_msg = format!("sending chunk to thread failed with {:?}", e);
                        if extra_out {
                            eprintln!("{}", error_msg);
                        }
                        break Err(Error::InvalidRequest(error_msg));
                    }
                } else {
                    // Bump the progress bar here to make it consistent
                    if let Some(x) = pb.as_ref() {
                        x.inc(n as u64)
                    }
                }

                offset += CHUNK_SIZE;
                i += 1;
            };

            for tx in senders {
                drop(tx);
            }

            if let Err(e) = read_result {
                // some part of reading from the disk and sending to the upload
                // threads failed, so unwind. stop the bulk write process, finalize
                // the disk, then delete it.
                self.unwind_disk_bulk_write_stop().await?;
                self.unwind_disk_finalize().await?;
                self.unwind_disk_delete().await?;

                // return the original error
                return Err(e);
            }

            let mut results = Vec::with_capacity(handles.len());
            for handle in handles {
                let result = handle
                    .await
                    .map_err(|x| x.to_string())
                    .map_err(Error::InvalidRequest)?;
                results.push(result);
            }

            if results.iter().any(|x| x.is_err()) {
                // If any of the upload threads returned an error, unwind the disk.
                if extra_out {
                    eprintln!("one of the upload threads failed");
                }
                self.unwind_disk_bulk_write_stop().await?;
                self.unwind_disk_finalize().await?;
                self.unwind_disk_delete().await?;
                return Err(Error::InvalidRequest(
                    "one of the upload threads failed".to_string(),
                ));
            }

            // wait for upload threads to complete, then finish the progress bar
            if let Some(x) = pb {
                x.finish()
            }

            // Stop the bulk write process
            let stop_bulk_write_response = self
                .client
                .disk_bulk_write_import_stop()
                .project(project)
                .disk(disk.clone())
                .send()
                .await;

            if let Err(e) = stop_bulk_write_response {
                if extra_out {
                    eprintln!("stopping the bulk write process failed with {:?}", e);
                }

                // Attempt to unwind the disk, although it will probably fail - the
                // first step is to stop the bulk write process!
                self.unwind_disk_bulk_write_stop().await?;
                self.unwind_disk_finalize().await?;
                self.unwind_disk_delete().await?;

                return Err(e);
            }

            // Finalize the disk, optionally making a snapshot
            let request = self
                .client
                .disk_finalize_import()
                .project(project)
                .disk(disk.clone())
                .body(FinalizeDisk {
                    snapshot_name: self.snapshot.as_ref().unwrap().clone(),
                });

            let finalize_response = request.send().await;

            if let Err(e) = finalize_response {
                if extra_out {
                    eprintln!("finalizing the disk failed with {:?}", e);
                }

                // Attempt to unwind the disk, although it will probably fail - the
                // first step is to finalize the disk!
                self.unwind_disk_finalize().await?;
                self.unwind_disk_delete().await?;

                return Err(e);
            }

            // optionally, make an image out of that snapshot
            if let Some(image_name) = &self
                .image
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?
            {
                let snapshot_name = self.snapshot.as_ref().unwrap().as_ref().unwrap();
                let image_description = self.image_description.as_ref().unwrap().as_ref().unwrap();
                let image_os = self.image_os.as_ref().unwrap().as_ref().unwrap();
                let image_version = self.image_version.as_ref().unwrap().as_ref().unwrap();

                // at this point, unwinding is not as important as before. the user
                // has uploaded their file to a disk and finalized that disk, making
                // a snapshot out of it. if this step fails, they can always
                // manually make an image out of the snapshot later and be sure that
                // the snapshot's contents are the same.
                let snapshot = self
                    .client
                    .snapshot_view()
                    .project(project)
                    .snapshot(NameOrId::Name(snapshot_name.clone()))
                    .send()
                    .await?;

                self.client
                    .image_create()
                    .project(project)
                    .body(ImageCreate {
                        name: image_name.clone(),
                        description: image_description.clone(),
                        os: image_os.clone(),
                        version: image_version.clone(),
                        source: ImageSource::Snapshot(snapshot.id),
                    })
                    .send()
                    .await?;
            }

            if extra_out {
                println!("done!");
            }

            Ok(ResponseValue::new(
                (),
                reqwest::StatusCode::OK,
                reqwest::header::HeaderMap::new(),
            ))
        }

        async fn unwind_disk_delete(&self) -> Result<(), Error<crate::types::Error>> {
            let project = self
                .project
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let disk = self
                .disk
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let extra_out = *self
                .extra_output
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;

            let response = self
                .client
                .disk_delete()
                .project(project)
                .disk(disk.clone())
                .send()
                .await;

            if let Err(e) = response {
                if extra_out {
                    eprintln!("trying to unwind, deleting {:?} failed with {:?}", disk, e);
                }
                return Err(e);
            }

            Ok(())
        }

        async fn unwind_disk_finalize(&self) -> Result<(), Error<crate::types::Error>> {
            let project = self
                .project
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let disk = self
                .disk
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let extra_out = *self
                .extra_output
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;

            let response = self
                .client
                .disk_finalize_import()
                .project(project)
                .disk(disk.clone())
                .send()
                .await;

            // If this fails, then the disk will remain in state "import-ready"
            if let Err(e) = response {
                if extra_out {
                    eprintln!(
                        "trying to unwind, finalizing {:?} failed with {:?}",
                        disk, e
                    );
                }
                return Err(e);
            }

            Ok(())
        }

        async fn unwind_disk_bulk_write_stop(&self) -> Result<(), Error<crate::types::Error>> {
            let project = self
                .project
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let disk = self
                .disk
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;
            let extra_out = *self
                .extra_output
                .as_ref()
                .map_err(|x| x.to_string())
                .map_err(Error::InvalidRequest)?;

            let response = self
                .client
                .disk_bulk_write_import_stop()
                .project(project)
                .disk(disk.clone())
                .send()
                .await;

            // If this fails, then the disk will remain in state
            // "importing-from-bulk-writes"
            if let Err(e) = response {
                if extra_out {
                    eprintln!(
                    "trying to unwind, stopping the bulk write process for {:?} failed with {:?}",
                    disk, e
                );
                }
                return Err(e);
            }

            Ok(())
        }
    }

    fn err_if_object_exists<T>(
        error_msg: String,
        send_response: Result<ResponseValue<T>, Error<crate::types::Error>>,
    ) -> Result<(), Error<crate::types::Error>> {
        match send_response {
            Ok(_) => {
                return Err(Error::InvalidRequest(error_msg));
            }

            Err(e) => {
                match &e {
                    // Match against 404
                    Error::ErrorResponse(response_value) => {
                        if response_value.status() == 404 {
                            return Ok(());
                        } else {
                            return Err(e);
                        }
                    }

                    // Bail on any other error
                    _ => return Err(e),
                }
            }
        }
    }

    /// Return a disk size that Nexus will accept for the path and size arguments
    fn get_disk_size(path: &PathBuf, size: Option<u64>) -> Result<u64, Error<crate::types::Error>> {
        const ONE_GB: u64 = 1024 * 1024 * 1024;

        let disk_size = if let Some(size) = size {
            size
        } else {
            std::fs::metadata(path)
                .map_err(|e| e.to_string())
                .map_err(Error::InvalidRequest)?
                .len()
        };

        // Nexus' disk size minimum is 1 GB, and Nexus only supports disks whose
        // size is a multiple of 1 GB
        let disk_size = if disk_size % ONE_GB != 0 {
            let rounded_down_gb: u64 = disk_size - disk_size % ONE_GB;
            assert_eq!(rounded_down_gb % ONE_GB, 0);
            rounded_down_gb + ONE_GB
        } else {
            disk_size
        };

        Ok(disk_size)
    }

    #[test]
    fn test_get_disk_size() {
        let path = PathBuf::from("not relevant because we're supplying a size");

        // test rounding up
        assert_eq!(get_disk_size(&path, Some(1)).unwrap(), 1024 * 1024 * 1024,);

        assert_eq!(
            get_disk_size(&path, Some(1024 * 1024 * 1024 - 1)).unwrap(),
            1024 * 1024 * 1024,
        );

        // test even multiples of GB
        assert_eq!(
            get_disk_size(&path, Some(1024 * 1024 * 1024)).unwrap(),
            1024 * 1024 * 1024,
        );

        assert_eq!(
            get_disk_size(&path, Some(2 * 1024 * 1024 * 1024)).unwrap(),
            2 * 1024 * 1024 * 1024,
        );

        // test non-even multiples of GB
        assert_eq!(
            get_disk_size(&path, Some(2 * 1024 * 1024 * 1024 + 1)).unwrap(),
            3 * 1024 * 1024 * 1024,
        );

        assert_eq!(
            get_disk_size(&path, Some(3 * 1024 * 1024 * 1024 - 1)).unwrap(),
            3 * 1024 * 1024 * 1024,
        );
    }
}
